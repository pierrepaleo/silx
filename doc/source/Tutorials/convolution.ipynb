{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accelerated convolution with silx\n",
    "\n",
    "Since version 0.11, silx comes with a Convolution operator leveraging CPU and GPU execution parallelism.  \n",
    "This convolution is computed in the \"real\" domain (i.e does not involve Fourier transforms)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Brief recall on terminology and boundaries handling modes\n",
    "\n",
    "You can skip this section if you are already familiar with convolution and boundary handling.\n",
    "\n",
    "### 0.1 - Terminology\n",
    "\n",
    "In this tutorial, we aim at computing convolutions between two arrays. These arrays are possibly multi-dimensional (1, 2 or 3). \n",
    "The first array involved will be called **signal** (it can be a time series, an image or a volume). \n",
    "The second array will be called **kernel**. It is assumed to be smaller in size than the signal. \n",
    "The number of dimensions of the signal and kernel are denoted by $N_s$ and $N_k$, respectively.\n",
    "\n",
    "For example, in the case of a Gaussian blur or an image, the signal is the image (2D: $N_s = 2$), and the kernel is a (separable) truncated Gaussian distribution (1D: $N_k = 1$). \n",
    "\n",
    "Lastly, the number of dimensions of the kernel is always smaller than the number of dimensions of the signal (that is, $N_k \\leq N_s$). It does make sense to convolve a 3D volume with a 2D image, but the opposite does not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2 - Boundaries handling\n",
    "\n",
    "When computing a convolution, an issue arises at the \"edges\" of the involved signal: the convolution kernel spills outside of the signal support. \n",
    "When the kernel is near the edges, some of the signal values can be multiplied with the corresponding kernel values, while some might not. \n",
    "To overcome this, the kernel values are multiplied with \"dummy\" signal values, which can be:\n",
    "  - Zeros: it is equivalent of ignoring the kernel values outside of the signal edges (this is what is done in `numpy.convolve(sig, kern, mode=\"same\")`)\n",
    "  - Constants (a generalization of the previous case)\n",
    "  - Signal values\n",
    "\n",
    "In the latter case, the signal values used outside of the signal support depend on the boundary handling scheme:\n",
    "  - Periodic: this is equivalent at tiling the signal multiple time before applying the convolution kernel (convolution performed with FFTs assume a periodic boundaries handling).\n",
    "  - Mirror, symmetric: the signal values outside of the signal support are those near the edges, \"mirrored\".\n",
    "  - Edges: the signal values outside the signal support are those of the signal edges\n",
    "\n",
    "The convolution in silx is designed to be compatible with the one of `scipy`. \n",
    "Please see the documentation of `scipy.ndimage.convole` for a more detailed description of each mode.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Creating a `Convolution` object\n",
    "\n",
    "In silx, the `Convolution` object is a typical case of `OpenclProcessing`: \n",
    "  - Create an OpenCL context and processing queue. The context is created on the \"best\" found device, unless told otherwise\n",
    "  - Register all the information relevant to the convolution processing (signal and kernel dimensions and sizes, axes, etc).\n",
    "  - Compile the relevant OpenCL kernels and pre-allocate memory\n",
    "  \n",
    "All of this is done by specifying the information on the signal and kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from silx.opencl.convolution import Convolution, gaussian_kernel\n",
    "from scipy.misc import ascent\n",
    "img = ascent().astype(\"f\")\n",
    "g = gaussian_kernel(1.0)\n",
    "C = Convolution(img.shape, g) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "All you need to provide is the shape of the signal, and the kernel array. \n",
    "\n",
    "Once built, the `Convolution` object can provide you with useful information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(C.use_case_desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the \"use case\" is the convolution of a 2D signal (image) with a 1D kernel.  \n",
    "This is what is done by default when building the Convolution operator. A separable convolution corresponds to a convolution along the horizontal axis, followed by a convolution along the vertical axis (or the other way around)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Specifying axes: non-separable, batched, and separable convolution\n",
    "\n",
    "The `axes` keyword argument of `Convolution` lets you choose the axes along which the convolution is computed. \n",
    "In the previous example, a one-dimensional kernel is used on a 2D image as a separable convolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(C.axes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, `(0, 1)` means that the image is convolved with the 1D kernel along the dimension 0, then along the dimension 1.  \n",
    "If the convolution is applied on only one axis (out of $N_s$) of the signal, this means that a batched convolution is computed. For example:\n",
    "  - batched 1D convolution on 2D data along rows\n",
    "  - batched 1D convolution on 3D data\n",
    "  - batched 2D convolution on 3D data\n",
    "\n",
    "In the following, we build the convolution object with `axes=(1,)`, so that the convolution will be performed row by row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C1 = Convolution(img.shape, g, axes=(1,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the signal/kernel dimensions and the axes, the object is able to infer the \"use case\" :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(C1.use_case_desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us compare with `scipy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.ndimage import convolve1d\n",
    "ref = convolve1d(img, g, axis=1)\n",
    "res = C1(img)\n",
    "print(np.allclose(res, ref))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the kernel number of dimensions ($N_k$) equals the signal number of dimensions ($N_s$), it is inferred that the convolution is not separable (the kernel is separable if its matrix rank is 1).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k2 = np.array([[1.,2,3],[0,1,2],[0,1,2]])\n",
    "k2 /= k2.sum()\n",
    "C2 = Convolution(img.shape, k2)\n",
    "print(C2.use_case_desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again we can comare the convolution results with `scipy`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import convolve\n",
    "ref2 = convolve(img, k2)\n",
    "res2 = C2(img)\n",
    "print(np.allclose(res2, ref2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Boundary handling\n",
    "\n",
    "`silx.opencl.convolution.Convolution` comes with several boundary handling methods: \"reflect\", \"nearest\", \"wrap\", \"constant\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = Convolution(img.shape, g, axes=(1,), mode=\"wrap\")\n",
    "res = C(img)\n",
    "ref = convolve1d(img, g, axis=1, mode=\"wrap\")\n",
    "print(np.allclose(res,ref))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Using silx convolution in performance-critical applications\n",
    "\n",
    "`silx.opencl.convolution` tries to be as fast as possible. The underlying implementation is done in OpenCL to exploit GPU or CPU parallelism.  \n",
    "Like any `OpenclProcessing` class, the usual usage of `Convolution` is the following:\n",
    "  - Build a `Convolution` object *once*\n",
    "  - Apply it *many* times\n",
    "\n",
    "The `Convolution` operator may be called on an input which is a `pyopencl.array.Array`. \n",
    "This is useful when you have some data already in GPU memory and you don't want to do extra CPU-GPU transfers. \n",
    "The output of the convolution processing may also be provided, again as a `pyopencl.array.Array`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyopencl.array as parray\n",
    "C = Convolution(img.shape, g)\n",
    "# Create a \"dataset\" of 100 frames on GPU.\n",
    "# Then, apply a separable convolution on each frame\n",
    "#Â (This might also be done by stacking the frames series as a 3D array !)\n",
    "N = 100\n",
    "# Simulate data acquisition\n",
    "dummy_gpu_data = []\n",
    "gpu_outputs = []\n",
    "for i in range(N):\n",
    "    dummy_gpu_data.append(\n",
    "        parray.to_device(C.queue, img + i) \n",
    "    )\n",
    "    gpu_outputs.append(\n",
    "        parray.zeros_like(dummy_gpu_data[-1])\n",
    "    )\n",
    "# Data processing\n",
    "i = 0\n",
    "for gpu_frame, gpu_output in zip(dummy_gpu_data, gpu_outputs):\n",
    "    print(\"Processing frame %d\" % i)\n",
    "    # The object \"C\" is applied multiple time, on a series of images.\n",
    "    # Both input and output images are on device, so no extraneous transfer is done.\n",
    "    C(gpu_frame, output=gpu_output)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
